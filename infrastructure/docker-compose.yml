# docker-compose.yml
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: fantasy_db
    environment:
      POSTGRES_USER: ${DB_USER:-fantasy_user}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-fantasy_pass}
      POSTGRES_DB: ${DB_NAME:-fantasy_football}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - fantasy_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-fantasy_user}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: fantasy_redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - fantasy_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: fantasy_backend
    environment:
      DATABASE_URL: postgresql+asyncpg://${DB_USER:-fantasy_user}:${DB_PASSWORD:-fantasy_pass}@postgres:5432/${DB_NAME:-fantasy_football}
      REDIS_URL: redis://redis:6379
      SECRET_KEY: ${SECRET_KEY:-your-secret-key-change-in-production}
      PYTHONPATH: /app
    volumes:
      - ./backend:/app
      - ./models:/app/models
    ports:
      - "8000:8000"
    networks:
      - fantasy_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  # Streamlit Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: fantasy_frontend
    environment:
      API_BASE_URL: http://backend:8000
      STREAMLIT_SERVER_PORT: 8501
      STREAMLIT_SERVER_ADDRESS: 0.0.0.0
      STREAMLIT_THEME_BASE: light
      STREAMLIT_THEME_PRIMARY_COLOR: "#3b82f6"
    volumes:
      - ./frontend:/app
    ports:
      - "8501:8501"
    networks:
      - fantasy_network
    depends_on:
      - backend
    command: streamlit run app.py --server.port 8501 --server.address 0.0.0.0

  # Celery Worker for Background Tasks
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: fantasy_celery
    environment:
      DATABASE_URL: postgresql+asyncpg://${DB_USER:-fantasy_user}:${DB_PASSWORD:-fantasy_pass}@postgres:5432/${DB_NAME:-fantasy_football}
      REDIS_URL: redis://redis:6379
      PYTHONPATH: /app
    volumes:
      - ./backend:/app
      - ./models:/app/models
    networks:
      - fantasy_network
    depends_on:
      - postgres
      - redis
      - backend
    command: celery -A tasks worker --loglevel=info

  # Celery Beat for Scheduled Tasks
  celery_beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: fantasy_celery_beat
    environment:
      DATABASE_URL: postgresql+asyncpg://${DB_USER:-fantasy_user}:${DB_PASSWORD:-fantasy_pass}@postgres:5432/${DB_NAME:-fantasy_football}
      REDIS_URL: redis://redis:6379
      PYTHONPATH: /app
    volumes:
      - ./backend:/app
    networks:
      - fantasy_network
    depends_on:
      - postgres
      - redis
      - backend
    command: celery -A tasks beat --loglevel=info

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: fantasy_nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    networks:
      - fantasy_network
    depends_on:
      - backend
      - frontend

networks:
  fantasy_network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:

---
# backend/Dockerfile
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    git \
    curl \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Default command
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]

---
# frontend/Dockerfile
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8501

# Default command
CMD ["streamlit", "run", "app.py", "--server.port", "8501", "--server.address", "0.0.0.0"]

---
# backend/requirements.txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0
sqlalchemy==2.0.23
asyncpg==0.29.0
alembic==1.12.1
redis==5.0.1
aioredis==2.0.1
fastapi-limiter==0.1.5
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.6
httpx==0.25.2
celery==5.3.4
tensorflow==2.15.0
scikit-learn==1.3.2
pandas==2.1.3
numpy==1.24.3
joblib==1.3.2
matplotlib==3.8.2
seaborn==0.13.0
plotly==5.18.0
scipy==1.11.4
aiohttp==3.9.1
ratelimit==2.2.1
backoff==2.2.1
python-dotenv==1.0.0

---
# frontend/requirements.txt
streamlit==1.29.0
pandas==2.1.3
numpy==1.24.3
plotly==5.18.0
requests==2.31.0
python-dotenv==1.0.0
streamlit-authenticator==0.2.3
extra-streamlit-components==0.1.60

---
# nginx.conf
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private auth;
    gzip_types text/plain text/css text/xml text/javascript application/x-javascript application/xml;
    gzip_disable "MSIE [1-6]\.";

    # Upstream servers
    upstream backend {
        server backend:8000;
    }

    upstream frontend {
        server frontend:8501;
    }

    # HTTP server - redirect to HTTPS
    server {
        listen 80;
        server_name _;
        return 301 https://$server_name$request_uri;
    }

    # HTTPS server
    server {
        listen 443 ssl http2;
        server_name _;

        # SSL configuration (update paths as needed)
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;
        add_header Content-Security-Policy "default-src 'self' http: https: ws: wss: data: blob: 'unsafe-inline' 'unsafe-eval'" always;

        # API routes
        location /api/ {
            rewrite ^/api/(.*) /$1 break;
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # WebSocket for API
        location /api/ws {
            rewrite ^/api/(.*) /$1 break;
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Frontend routes
        location / {
            proxy_pass http://frontend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # Streamlit WebSocket
        location /_stcore/stream {
            proxy_pass http://frontend/_stcore/stream;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}

---
# .env.example
# Database
DB_USER=fantasy_user
DB_PASSWORD=your_secure_password_here
DB_NAME=fantasy_football

# Redis
REDIS_URL=redis://localhost:6379

# Security
SECRET_KEY=your-secret-key-generate-with-openssl-rand-hex-32

# AWS (for production)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1

# Stripe (for future payments)
STRIPE_SECRET_KEY=sk_test_your_stripe_key
STRIPE_WEBHOOK_SECRET=whsec_your_webhook_secret

# Email (for notifications)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your_email@gmail.com
SMTP_PASSWORD=your_app_password

---
# Makefile
.PHONY: help build up down logs clean test

help:
	@echo "Available commands:"
	@echo "  make build    - Build Docker images"
	@echo "  make up       - Start all services"
	@echo "  make down     - Stop all services"
	@echo "  make logs     - View logs"
	@echo "  make clean    - Clean up volumes and images"
	@echo "  make test     - Run tests"
	@echo "  make migrate  - Run database migrations"
	@echo "  make shell    - Open shell in backend container"

build:
	docker-compose build

up:
	docker-compose up -d

down:
	docker-compose down

logs:
	docker-compose logs -f

clean:
	docker-compose down -v
	docker system prune -f

test:
	docker-compose run --rm backend pytest

migrate:
	docker-compose run --rm backend alembic upgrade head

shell:
	docker-compose exec backend /bin/bash

# Development
dev-backend:
	cd backend && uvicorn main:app --reload --host 0.0.0.0 --port 8000

dev-frontend:
	cd frontend && streamlit run app.py

# Production deployment
deploy-prod:
	./scripts/deploy.sh production

deploy-staging:
	./scripts/deploy.sh staging

# Database operations
db-backup:
	./scripts/backup-db.sh

db-restore:
	./scripts/restore-db.sh

# ML operations
train-models:
	docker-compose run --rm backend python -m ml.train

update-predictions:
	docker-compose run --rm backend python -m data.update_predictions

---
# scripts/deploy.sh
#!/bin/bash
set -e

ENVIRONMENT=$1

if [ -z "$ENVIRONMENT" ]; then
    echo "Usage: ./deploy.sh [production|staging]"
    exit 1
fi

echo "Deploying to $ENVIRONMENT..."

# Load environment variables
if [ "$ENVIRONMENT" == "production" ]; then
    source .env.production
else
    source .env.staging
fi

# Build and push Docker images to ECR
aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REGISTRY

docker build -t fantasy-backend ./backend
docker tag fantasy-backend:latest $ECR_REGISTRY/fantasy-backend:latest
docker push $ECR_REGISTRY/fantasy-backend:latest

docker build -t fantasy-frontend ./frontend
docker tag fantasy-frontend:latest $ECR_REGISTRY/fantasy-frontend:latest
docker push $ECR_REGISTRY/fantasy-frontend:latest

# Deploy to ECS or EC2
if [ "$DEPLOYMENT_TYPE" == "ecs" ]; then
    # Update ECS service
    aws ecs update-service --cluster fantasy-cluster --service fantasy-backend --force-new-deployment
    aws ecs update-service --cluster fantasy-cluster --service fantasy-frontend --force-new-deployment
else
    # Deploy to EC2 using docker-compose
    ssh -i ~/.ssh/fantasy-key.pem ec2-user@$EC2_HOST << EOF
        cd /home/ec2-user/fantasy-football-ai
        git pull origin main
        docker-compose pull
        docker-compose up -d
        docker system prune -f
EOF
fi

echo "Deployment complete!"

---
# terraform/main.tf (AWS Infrastructure)
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# Variables
variable "aws_region" {
  default = "us-east-1"
}

variable "environment" {
  default = "production"
}

# VPC
resource "aws_vpc" "fantasy_vpc" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name        = "fantasy-vpc-${var.environment}"
    Environment = var.environment
  }
}

# Public Subnet
resource "aws_subnet" "public_subnet" {
  vpc_id                  = aws_vpc.fantasy_vpc.id
  cidr_block              = "10.0.1.0/24"
  availability_zone       = "${var.aws_region}a"
  map_public_ip_on_launch = true

  tags = {
    Name        = "fantasy-public-subnet-${var.environment}"
    Environment = var.environment
  }
}

# Internet Gateway
resource "aws_internet_gateway" "igw" {
  vpc_id = aws_vpc.fantasy_vpc.id

  tags = {
    Name        = "fantasy-igw-${var.environment}"
    Environment = var.environment
  }
}

# Route Table
resource "aws_route_table" "public_rt" {
  vpc_id = aws_vpc.fantasy_vpc.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.igw.id
  }

  tags = {
    Name        = "fantasy-public-rt-${var.environment}"
    Environment = var.environment
  }
}

# Route Table Association
resource "aws_route_table_association" "public_rta" {
  subnet_id      = aws_subnet.public_subnet.id
  route_table_id = aws_route_table.public_rt.id
}

# Security Group
resource "aws_security_group" "fantasy_sg" {
  name        = "fantasy-sg-${var.environment}"
  description = "Security group for Fantasy Football AI"
  vpc_id      = aws_vpc.fantasy_vpc.id

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name        = "fantasy-sg-${var.environment}"
    Environment = var.environment
  }
}

# EC2 Instance
resource "aws_instance" "fantasy_server" {
  ami           = "ami-0c02fb55956c7d316" # Amazon Linux 2023
  instance_type = "t3.medium"
  subnet_id     = aws_subnet.public_subnet.id
  vpc_security_group_ids = [aws_security_group.fantasy_sg.id]
  
  key_name = "fantasy-key" # Create this key pair in AWS first

  user_data = <<-EOF
    #!/bin/bash
    yum update -y
    yum install -y docker git
    service docker start
    usermod -a -G docker ec2-user
    
    # Install docker-compose
    curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
    chmod +x /usr/local/bin/docker-compose
    
    # Clone repository
    cd /home/ec2-user
    git clone https://github.com/cbratkovics/fantasy-football-ai.git
    chown -R ec2-user:ec2-user fantasy-football-ai
  EOF

  tags = {
    Name        = "fantasy-server-${var.environment}"
    Environment = var.environment
  }
}

# RDS PostgreSQL
resource "aws_db_instance" "fantasy_db" {
  identifier     = "fantasy-db-${var.environment}"
  engine         = "postgres"
  engine_version = "15.4"
  instance_class = "db.t3.micro"
  
  allocated_storage     = 20
  max_allocated_storage = 100
  storage_type          = "gp3"
  storage_encrypted     = true
  
  db_name  = "fantasy_football"
  username = "fantasy_user"
  password = var.db_password # Set via environment variable
  
  vpc_security_group_ids = [aws_security_group.fantasy_sg.id]
  db_subnet_group_name   = aws_db_subnet_group.fantasy_db_subnet.name
  
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"
  
  skip_final_snapshot = false
  final_snapshot_identifier = "fantasy-db-final-snapshot-${var.environment}"
  
  tags = {
    Name        = "fantasy-db-${var.environment}"
    Environment = var.environment
  }
}

# DB Subnet Group
resource "aws_db_subnet_group" "fantasy_db_subnet" {
  name       = "fantasy-db-subnet-${var.environment}"
  subnet_ids = [aws_subnet.public_subnet.id, aws_subnet.private_subnet.id]
  
  tags = {
    Name        = "fantasy-db-subnet-${var.environment}"
    Environment = var.environment
  }
}

# Private Subnet for RDS
resource "aws_subnet" "private_subnet" {
  vpc_id            = aws_vpc.fantasy_vpc.id
  cidr_block        = "10.0.2.0/24"
  availability_zone = "${var.aws_region}b"

  tags = {
    Name        = "fantasy-private-subnet-${var.environment}"
    Environment = var.environment
  }
}

# ElastiCache Redis
resource "aws_elasticache_cluster" "fantasy_redis" {
  cluster_id           = "fantasy-redis-${var.environment}"
  engine               = "redis"
  node_type            = "cache.t3.micro"
  num_cache_nodes      = 1
  parameter_group_name = "default.redis7"
  port                 = 6379
  subnet_group_name    = aws_elasticache_subnet_group.fantasy_cache_subnet.name
  security_group_ids   = [aws_security_group.fantasy_sg.id]
  
  tags = {
    Name        = "fantasy-redis-${var.environment}"
    Environment = var.environment
  }
}

# ElastiCache Subnet Group
resource "aws_elasticache_subnet_group" "fantasy_cache_subnet" {
  name       = "fantasy-cache-subnet-${var.environment}"
  subnet_ids = [aws_subnet.public_subnet.id, aws_subnet.private_subnet.id]
}

# S3 Bucket for ML Models
resource "aws_s3_bucket" "fantasy_models" {
  bucket = "fantasy-football-ai-models-${var.environment}"
  
  tags = {
    Name        = "fantasy-models-${var.environment}"
    Environment = var.environment
  }
}

# S3 Bucket Versioning
resource "aws_s3_bucket_versioning" "fantasy_models_versioning" {
  bucket = aws_s3_bucket.fantasy_models.id
  
  versioning_configuration {
    status = "Enabled"
  }
}

# Outputs
output "server_public_ip" {
  value = aws_instance.fantasy_server.public_ip
}

output "database_endpoint" {
  value = aws_db_instance.fantasy_db.endpoint
}

output "redis_endpoint" {
  value = aws_elasticache_cluster.fantasy_redis.cache_nodes[0].address
}